			+--------------------+
			|        CS 153      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Viet Nguyen <vnguy057@ucr.edu> <861045871>
Craig Collier  <ccoll010@ucr.edu> <861100234>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

A struct used to keep track of threads that are asleep. 
Data kept includes the address of the thread, how long to sleep and when it started sleeping.
Found in src/device/timer.h
  struct thread_timer
  {
    /* Pointer to the sleeping thread */
    struct thread *sleeping_thread;
    /* How long the thread is supposed to sleep */
    int64_t ticks;
    /* When the timer was started */
    int64_t start;
    /* Shared between thread.c and synch.c. */
    struct list_elem elem;              /* List element. */
  };

A ordered list of the sleeping threads and its associated data is stored in this static variable 
sorted with next to wake to last to wake. 
Found in src/device/timer.h
  static struct list timer_block_list;

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

A call to timer_sleep() puts the thread into the list of sleeping threads. 
As the list is iterated through in order to find the spot to insert the new thread, 
the iterated items are updated with the current tick in order to ensure the correct 
location is found. After the thread is inserted, it is blocked. 
The thread is blocked after insertion in order to ensure its placement into the list.

The timer interrupt handler has been modified to update the sleeping threads' metadata.
Only the front of the list is updated, as the it is the next thread to wake. If the
front does wake as a result of this, it is unblocked and returned to the ready queue. 
The front is pop and the next item is updated in a similar fashion. 
This procedure minimizes the time spent in the function as only one item will be updated
in most calls. 

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

The timer_sleep() function requires the acquirement of a lock that
guards the list holding the sleeping threads and their metadata.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

The timer interrupt handler requires the same lock used to guard
the sleeping threads list against simultaneous calls to timer_sleep().

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

The design does the minimum amount of work in the interrupt handler in 
exchange for a slightly longer timer_sleep() function due to ensuring a
sorted list. 
The design relies on the timer driver to keep track of sleeping threads
as opposed to the thread scheduler or other internal thread structures 
keeping track of the sleeping threads. This was rationalized by the concept
that a module should know how to it wants to interact with the core system
and the core system should not know in advance which modules wish to interact
with it. The core system in this case is the thread, a fundamental element of
the operating system. The module is the timer which is not strictly necessary
to the execution of the operating system. The core system may not know how 
modules will interact with it, but it may allow access in advance. 
For example, the thread header provides a function to block a thread (put it 
into the waiting state) and a function to unblock a thread (putting it back 
into the ready queue). Thus, using these provided functions, no changes are
required on the core system functionalities. 

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

Each thread now has a list member to keep track of all locks held by it.
This is so when thread i's priority is required, it can check the list of 
threads waiting on the locks held by thread i for donations. 
Found in src/threads/thread.h
  struct list synch_list; 
  
To prevent an infinite cycle of getting a thread's priority, a maximum 
depth for finding donation is required. 
Found in src/threads/thread.c
  #define MAX_DONATION_DEPTH 8;
  static uint8_t current_depth;
  
In order for a struct to be in a list, it requires a list_elem member. This 
is to enable the create of the synch_list member in a thread.
Found in src/threads/synch.h
  struct list_elem synchelem;

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)
Each threads holds a list of locks currently held by it. Because each lock
primitive holds a list of threads waiting to acquire the lock, the thread 
holding the lock is similar to the root node of a tree. In order to find 
the priority of the root node, a depth first search is used. If the current
depth reached is equal to the max depth to search, its unaltered priority is 
used. 

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

The list is kept sorted with the highest priority at the front. 
The front of the list is pop in order to determine the next 
thread to acquire the lock.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

Because lock acquire blocks a thread that has to wait for the lock, 
the block thread function is called. This function has been modified 
to sort the ready queue with the front being the thread with the
highest priority. Ties are broken in a random manner. The sorting 
requires re-evaluating each thread's priority, thus causing 
priority donations. 
Nested donation is handled by traversing the list of threads waiting
for a lock held by the thread whose priority is being evaluated. Since 
each waiting thread is like a node of a graph, a max distance of 
MAX_DONATION_DEPTH is tranversed from the starting node (the thread 
whose priority was initially in question). 

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

Since the next high priority thread is now the new owner of a lock, 
it is no longer in the waiting state and a call to unbock thread 
is initiated. This function has been modified to sorts the ready queue. 

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

A lock can be used to prevent this race as lower priority threads
will have to wait and threads with higher priority than the current 
running thread will donate their priority in order to ensure that
set priority finishes execution.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

This design appears simple to implement and has some clear benefits.
Since the lists are sorted, an iterator does not need to run through
each list to find the one with the highest priority to remove. Instead, 
the time to find the next thread to acquire a lock or use the processor
is about the same time it takes to pop the front of a list of threads. 
While keeping a sorted list runs in linearithmic time based on the size 
of the list, finding the priority could in the worst case run in
exponential time as it needs to tranverse a quasi-graph of threads waiting 
on locks the current thread holds. Each waiting thread's priority is 
calculated in the same manner, leading to exponential complexity. 
To prevent this, two member variables can be added to a thread's struct: 
donated_priority and dirty_priority. donated_priority is the last 
priority calculated for that thread using donations and dirty_priority 
tells the operating system if the thread's donated_priority needs to 
updated (according to events that would affect its priority). However, 
this design upgrade is not due to be implemented due to possible 
overcomplexity and time constraints. 

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
